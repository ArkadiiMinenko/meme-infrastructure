# ğŸš€ Step 1 â€” Infrastructure Foundation  
**Terraform Ã— Proxmox Ã— Reality Check**

---

## Context

This project is a DevOps homelab built with one clear intention:  
to design infrastructure that behaves like **production**, not like a demo.

No managed services.  
No hidden automation.  
Full control over virtualization, networking, and provisioning.

Before touching Kubernetes, GitOps, or CI/CD, the foundation has to be solid.

This step is about building that foundation.

---

## ğŸ¯ Goals of Step 1

- Understand how Proxmox actually manages VM lifecycle
- Set up Terraform locally as the **single source of truth** for infrastructure
- Eliminate manual VM creation and UI-driven configuration
- Prepare a clean base for future Kubernetes nodes

This step was less about speed â€”  
and more about learning the platformâ€™s edges.

---

## ğŸ§± What Was Built

### Proxmox Side

- Imported an Ubuntu **cloud-init** image
- Converted it into a reusable **VM template**

Verified:
- disk layout and boot mode (SeaBIOS)
- virtio storage and networking
- cloud-init compatibility

---

### Terraform Side

- Configured Terraform to control Proxmox via API
- Described VM configuration entirely in code:
  - CPU and RAM limits
  - static IPs via cloud-init
  - SSH access using public keys
- Ensured infrastructure could be recreated from scratch at any time

At this point, the goal was simple:

> **`terraform apply` should produce a usable VM â€” every time.**

---

## âš ï¸ What Went Wrong (and Why It Mattered)

### 1. Terraform Hanging on `Still creating...`

Terraform would wait indefinitely, even though the VM was already running.

**Why?**  
Terraform relies on **QEMU Guest Agent** to receive the VMâ€™s IP address and mark it as â€œreadyâ€.

No agent â†’ no signal â†’ Terraform waits forever.

**Fix:**
- Installed and enabled `qemu-guest-agent` in the template
- Enabled agent support in Proxmox

---

### 2. PXE Boot Instead of Disk Boot

Some VMs didnâ€™t boot at all and dropped straight into PXE.

**Symptoms:**
- `Boot failed: could not read the boot disk`
- Root disk attached as `unused0`
- `scsi0` missing
- cloud-init CDROM not connected

**What actually happened:**  
The Terraform provider created the disk, but failed to attach it correctly.

Result:  
A VM that exists â€” but cannot boot.

Temporary fixes were possible via `qm set`, butâ€¦

---

### 3. The Real Issue: Provider Instability

The initial Proxmox Terraform provider showed:
- inconsistent VM definitions
- provider crashes
- partial resource creation
- repeated manual intervention

At this point, the problem was no longer configuration â€”  
it was **tool reliability**.

---

## ğŸ§  Engineering Decision

Instead of stacking workarounds and post-create scripts, the decision was made to:

> **Replace the provider.**

Sometimes the most correct solution is not a clever workaround,  
but choosing a tool that behaves predictably.

This immediately stabilized the provisioning process.

---

## âœ… Outcome of Step 1

- Terraform provisions Proxmox VMs reliably
- No manual fixes required after creation
- VM state is fully reproducible from code
- Infrastructure is ready for Kubernetes bootstrap

Most importantly:  
**the foundation is now trusted.**

---

## ğŸ“Œ Key Takeaways

- Infrastructure as Code does not hide platform behavior â€” it reveals it
- Minimal cloud images require deliberate preparation
- Terraform is only as reliable as the signals it receives
- Knowing *when to switch tools* is as important as knowing how to configure them

# ğŸš€ Step 2 â€” Configuration Management & Kubernetes Bootstrapping

**Terraform Ã— Ansible Ã— Kubernetes (Zero-Touch Deployment)**

---

## Context

After virtual machines were provisioned with Terraform, the infrastructure was still incomplete.

Bare VMs are not a platform.

This step focuses on **turning raw compute into a working Kubernetes cluster**,  
without manual SSH access or node-by-node configuration.

The goal is full automation from infrastructure provisioning  
to a ready-to-use Kubernetes control plane.

---

## ğŸ¯ Goals of Step 2

- Automate OS preparation for Kubernetes nodes
- Eliminate manual SSH access during cluster setup
- Bootstrap a Kubernetes cluster using declarative configuration
- Connect Terraform (infrastructure) and Ansible (configuration) into a single workflow
- Achieve repeatable, zero-touch cluster deployment

---

## ğŸ§± What Was Built

### Terraform â†” Ansible Integration

- Terraform dynamically generates `inventory.ini`
- No hardcoded IP addresses
- Nodes are automatically grouped into:
  - `[master]`
  - `[workers]`
- Ansible becomes infrastructure-aware without manual updates

Result:

> Infrastructure changes automatically propagate into configuration management.

---

### OS Preparation (Ansible)

A dedicated Ansible playbook prepares all nodes for Kubernetes:

- Disabled SWAP (runtime and persistent)
- Loaded required kernel modules:
  - `overlay`
  - `br_netfilter`
- Configured `sysctl` parameters for Kubernetes networking
- Installed and configured container runtime (`containerd`)
- Installed Kubernetes components:
  - `kubeadm`
  - `kubelet`
  - `kubectl`

All steps are idempotent and safe to re-run.

---

### Kubernetes Cluster Bootstrapping

Ansible automates the entire cluster lifecycle:

- Initializes the Control Plane using `kubeadm`
- Installs CNI networking (Flannel)
- Generates and distributes the join token
- Automatically joins Worker nodes to the cluster
- Configures kubeconfig access for cluster management

The cluster reaches a ready state without any manual intervention.

---

## âš ï¸ What Went Wrong (and Why It Mattered)

### 1. SSH Access Failing on a Single Node

One node refused SSH connections with `Connection refused`,  
while network connectivity (ping) was fully functional.

**Initial assumption:**  
Cloud-init or OS configuration issue.

**Actual cause:**  
IP address conflict inside the home network.

The IP was already silently assigned to an IoT device.

**Fix:**

- Adjusted Terraform IP allocation logic
- Moved Kubernetes nodes into a dedicated address range

---

### 2. Kubernetes Reset Artifacts

After reinitializing the cluster, pods were stuck in `ContainerCreating`.

**Root cause:**

- Old CNI interfaces (`cni0`) persisted after `kubeadm reset`
- Network conflicts prevented pod networking

**Fix:**

- Explicit cleanup of CNI interfaces before re-initialization
- Ensured clean network state before cluster bootstrap

---

## ğŸ§  Engineering Decisions

- Terraform handles **infrastructure**
- Ansible handles **configuration**
- No configuration logic inside Terraform
- No infrastructure assumptions inside Ansible

Each tool does one job â€” and does it well.

---

## âœ… Outcome of Step 2

- Fully automated Kubernetes cluster provisioning
- Zero manual SSH configuration
- Infrastructure and configuration are fully reproducible
- Cluster can be destroyed and recreated reliably

```text
terraform apply
ansible-playbook
â†’ Kubernetes cluster ready

---

# ğŸ§© Step 3 â€” Platform Add-ons (Networking)

At this stage, the Kubernetes cluster foundation is complete.
Today the focus was not on building new infrastructure,
but on **adding minimal platform services required for real traffic flow**.

No new complexity â€” just the essentials.

---

## ğŸ›  What Was Added

### MetalLB
- Configured in **Layer 2 mode**
- Provides a virtual IP address inside the local network
- Enables LoadBalancer-type services in a bare-metal cluster

Result:
> Kubernetes services can now receive traffic from outside the cluster.

---

### Ingress NGINX
- Installed as the cluster ingress controller
- Handles HTTP routing based on hostnames
- Acts as the single entry point for future applications

Result:
> External traffic â†’ Ingress â†’ Service â†’ Pod

---

## ğŸ” What Was Verified

- LoadBalancer IP announced correctly via ARP
- Traffic reaches the ingress controller
- Host-based routing works as expected
- Test application responds through NodePort / Ingress

No manual port forwarding.  
No SSH tunneling.

---

## ğŸ Outcome

The cluster now has a **basic but production-like networking layer**:
- External IP allocation
- Central ingress point
- Predictable traffic flow

This is enough to start deploying **real applications**.

---